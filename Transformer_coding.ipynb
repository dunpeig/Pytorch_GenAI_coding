{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LT50nMMuh1NC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db5b1af-b5cc-4756-a68d-17476b3a9917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Model parameters: 930,316\n",
            "Epoch 10/50, Loss: 0.2702\n",
            "Epoch 20/50, Loss: 0.0633\n",
            "Epoch 30/50, Loss: 0.0454\n",
            "Epoch 40/50, Loss: 0.0230\n",
            "Epoch 50/50, Loss: 0.0204\n",
            "Input:     [3, 3, 6, 6, 7]\n",
            "Target:    [7, 6, 6, 3, 3, 11]\n",
            "Predicted: [7, 6, 6, 3, 3, 11]\n",
            "\n",
            "Input:     [1, 6, 7, 2, 8]\n",
            "Target:    [8, 2, 7, 6, 1, 11]\n",
            "Predicted: [8, 2, 7, 6, 1, 11]\n",
            "\n",
            "Input:     [4, 6, 6, 8, 4]\n",
            "Target:    [4, 8, 6, 6, 4, 11]\n",
            "Predicted: [4, 8, 6, 6, 4, 11]\n",
            "\n",
            "Input:     [1, 6, 9, 1, 4]\n",
            "Target:    [4, 1, 9, 6, 1, 11]\n",
            "Predicted: [4, 1, 9, 6, 1, 11]\n",
            "\n",
            "Input:     [8, 9, 7, 8, 5]\n",
            "Target:    [5, 8, 7, 9, 8, 11]\n",
            "Predicted: [5, 8, 7, 9, 8, 11]\n",
            "\n",
            "Input:     [2, 2, 8, 1, 8]\n",
            "Target:    [8, 1, 8, 2, 2, 11]\n",
            "Predicted: [8, 1, 8, 2, 2, 11]\n",
            "\n",
            "Input:     [8, 9, 3, 2, 4]\n",
            "Target:    [4, 2, 3, 9, 8, 11]\n",
            "Predicted: [4, 2, 3, 9, 8, 11]\n",
            "\n",
            "Input:     [8, 3, 6, 1, 8]\n",
            "Target:    [8, 1, 6, 3, 8, 11]\n",
            "Predicted: [8, 1, 6, 3, 8, 11]\n",
            "\n",
            "Input:     [7, 3, 4, 1, 2]\n",
            "Target:    [2, 1, 4, 3, 7, 11]\n",
            "Predicted: [2, 1, 4, 3, 7, 11]\n",
            "\n",
            "Input:     [4, 9, 4, 7, 3]\n",
            "Target:    [3, 7, 4, 9, 4, 11]\n",
            "Predicted: [3, 7, 4, 9, 4, 11]\n",
            "\n",
            "Accuracy on 10 test samples: 10/10\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "      # set a maximun sequence length of 5000\n",
        "      # d_model is the embedding dimension, for example 128, 512\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        # torch.arrange creates [0,1,2,3...,4999] so 5000 by 1 vector\n",
        "        # after squeeze is 5000 by 1\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        # div term dimension is d_model/2 vector, create different frequencies for diff positions\n",
        "        # suppose d_model is 128\n",
        "        # the arrange would create a row dimension, 1D vector\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        # 5000 by 1 times 64 is 5000 by 64\n",
        "        # the div_term would be broadcasted as 1 by 64\n",
        "        # the even columns: 0, 2, 4,...,126\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # the odd columns: 1, 3, ..., 127\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        # basically the relative postions\n",
        "        # change to 1, 5000, 128\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # saves the pe as part of the model state\n",
        "        # not a trainable parameter, fronzen positional encoding\n",
        "        # will be saved/loaded with model checkpoints\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # if x is 32, 10, 128, then it is 32, 10, 128 + 1, 10, 128\n",
        "        # the positional encoding is added to every sequence\n",
        "        # addition is the original implementation, and also in other paper\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Q is batch, num_heads, seq_len, d_k\n",
        "        # K is batch, num_heads, d_k, seq_len\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # result is batch, num_heads, seq_len, seq_len\n",
        "        if mask is not None:\n",
        "          # is provided, mask is batch, 1, seq_len, seq_len\n",
        "          # sets the attention score to -1e9 so they become ~0 after softmax\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        # each row now sums to 1 , representing attention weights\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        # batch, num_heads, seq_len, seq_len\n",
        "        # batch, num_heads, seq_len, d_k\n",
        "        # result us batch, num_heads, seq_len, d_k , a weighted combination of all value vectors\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        # batch, seq_len, d_model\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        # linear layer\n",
        "        # Q is batch, seq_len, 512, then times 512 by 512\n",
        "        # output = Q @ W_q.weight.T + W_q.bias\n",
        "        # final dimension is batch, seq_len, 512\n",
        "        # then the split_head\n",
        "        # would return , batch, num_heads, seq_length, d_k\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        # batch, num_heads, seq_len, d_k\n",
        "\n",
        "        # after combine heads is batch, seq_len, d_model\n",
        "        # the output = combine_heads @ W_o.weight.T + W_o.bias\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "# Feed Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      # the transfomer position-wise feed-forward network with ReLU activation function\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "      # batch, seq_len, d_model\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # the first multihead attention with mask\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        # the second multihead attention as in tranformer arc\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "# Complete Transformer\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8,\n",
        "                 num_layers=6, d_ff=2048, max_seq_length=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        # ModuleList registers parameters, enables .to(device)\n",
        "        # enables .parameters(), saves/loads state\n",
        "        # enables .train() and /eval(), properly sets training/eval mode for\n",
        "        # all layers\n",
        "        # same as\n",
        "        # self.encoder_layers = nn.ModuleList([\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 0\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 1\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 2\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 3\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 4\n",
        "        #     EncoderLayer(d_model, num_heads, d_ff, dropout),  # Layer 5\n",
        "        # ])\n",
        "        # each layer has its own parameters, different transformations\n",
        "\n",
        "        # ### **1. Hierarchical Feature Learning**\n",
        "\n",
        "        # Each layer learns increasingly abstract representations:\n",
        "        # ```\n",
        "        # Layer 1: Simple patterns (word relationships, basic grammar)\n",
        "        # Layer 2: Phrases and local context\n",
        "        # Layer 3: Sentence-level meaning\n",
        "        # Layer 4: Discourse structure\n",
        "        # Layer 5: Complex reasoning\n",
        "        # Layer 6: High-level semantic understanding\n",
        "        # ```\n",
        "        ### **2. Increased Representational Power**\n",
        "\n",
        "        # - **Single layer**: Limited expressiveness\n",
        "        # - **Multiple layers**: Can learn much more complex functions\n",
        "        # - Similar to how deep CNNs learn edges → shapes → objects\n",
        "\n",
        "        # ### **3. Longer-Range Dependencies**\n",
        "\n",
        "        # Each attention layer has a \"receptive field\" - stacking allows information\n",
        "        # to propagate across the entire sequence multiple times:\n",
        "        # ```\n",
        "        # Layer 1: Each token attends to all others (1 hop)\n",
        "        # Layer 2: Tokens can combine information from layer 1 (2 hops)\n",
        "        # Layer 3: Even more complex relationships (3 hops)\n",
        "        # ...\n",
        "        # Layer 6: Very complex, multi-hop reasoning (6 hops)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "      # != 0 is the boolean mask\n",
        "      # after two unsqueeze, for example 2,6 would be 2, 1, 1, 6\n",
        "      # batch, 1, 1, seq_len\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        #\n",
        "        seq_length = tgt.size(1)\n",
        "        # upper triangular of 1, seq_len, seq_len\n",
        "        # then 1 - , is the lower left triangualr\n",
        "        # nopeak = 1 - upper_tri\n",
        "        # tensor([\n",
        "        #     [[1., 0., 0., 0., 0., 0.],   ← Position 0 can only see position 0\n",
        "        #      [1., 1., 0., 0., 0., 0.],   ← Position 1 can see positions 0-1\n",
        "        #      [1., 1., 1., 0., 0., 0.],   ← Position 2 can see positions 0-2\n",
        "        #      [1., 1., 1., 1., 0., 0.],   ← Position 3 can see positions 0-3\n",
        "        #      [1., 1., 1., 1., 1., 0.],   ← Position 4 can see positions 0-4\n",
        "        #      [1., 1., 1., 1., 1., 1.]]   ← Position 5 can see all positions\n",
        "        # ])\n",
        "        # triu, diagonal=0 means the elements on and above the main diagonal are remianed\n",
        "        # diagonal = 1 means above the diagonal are remained\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask.to(tgt.device)\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "# Toy Dataset: Simple number reversal task\n",
        "def generate_toy_data(num_samples=1000, seq_length=5):\n",
        "    \"\"\"Generate sequences where target is the reverse of source\"\"\"\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        # Generate random sequence (vocab: 1-9, 0 is padding)\n",
        "        seq = torch.randint(1, 10, (seq_length,))\n",
        "        # Target is reversed sequence with BOS (10) and EOS (11) tokens\n",
        "        tgt_input = torch.cat([torch.tensor([10]), seq.flip(0)])\n",
        "        tgt_output = torch.cat([seq.flip(0), torch.tensor([11])])\n",
        "        data.append((seq, tgt_input, tgt_output))\n",
        "    return data\n",
        "\n",
        "# Training function\n",
        "def train_model():\n",
        "    # Hyperparameters\n",
        "    src_vocab_size = 12  # 0-9 digits + BOS + EOS\n",
        "    tgt_vocab_size = 12\n",
        "    d_model = 128\n",
        "    num_heads = 4\n",
        "    num_layers = 2\n",
        "    d_ff = 512\n",
        "    max_seq_length = 20\n",
        "    batch_size = 32\n",
        "    num_epochs = 50\n",
        "\n",
        "    # Generate toy data\n",
        "    train_data = generate_toy_data(800, seq_length=5)\n",
        "    test_data = generate_toy_data(200, seq_length=5)\n",
        "\n",
        "    # Initialize model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads,\n",
        "                       num_layers, d_ff, max_seq_length).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    print(f\"Training on {device}\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch = train_data[i:i+batch_size]\n",
        "            src_batch = torch.stack([item[0] for item in batch]).to(device)\n",
        "            tgt_input_batch = torch.stack([item[1] for item in batch]).to(device)\n",
        "            tgt_output_batch = torch.stack([item[2] for item in batch]).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src_batch, tgt_input_batch)\n",
        "            loss = criterion(output.reshape(-1, tgt_vocab_size), tgt_output_batch.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / (len(train_data) // batch_size)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt_input, tgt_output in test_data[:10]:\n",
        "            src = src.unsqueeze(0).to(device)\n",
        "            tgt_input = tgt_input.unsqueeze(0).to(device)\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            predicted = output.argmax(dim=-1)\n",
        "\n",
        "            print(f\"Input:     {src.squeeze().cpu().tolist()}\")\n",
        "            print(f\"Target:    {tgt_output.tolist()}\")\n",
        "            print(f\"Predicted: {predicted.squeeze().cpu().tolist()}\")\n",
        "            print()\n",
        "\n",
        "            if torch.equal(predicted.squeeze()[:-1], tgt_output[:-1].to(device)):\n",
        "                correct += 1\n",
        "\n",
        "    print(f\"Accuracy on 10 test samples: {correct}/10\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nopeak = 1 - upper_tri\n",
        "# tensor([\n",
        "#     [[1., 0., 0., 0., 0., 0.],   ← Position 0 can only see position 0\n",
        "#      [1., 1., 0., 0., 0., 0.],   ← Position 1 can see positions 0-1\n",
        "#      [1., 1., 1., 0., 0., 0.],   ← Position 2 can see positions 0-2\n",
        "#      [1., 1., 1., 1., 0., 0.],   ← Position 3 can see positions 0-3\n",
        "#      [1., 1., 1., 1., 1., 0.],   ← Position 4 can see positions 0-4\n",
        "#      [1., 1., 1., 1., 1., 1.]]   ← Position 5 can see all positions\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "Zg2TG5yXpGkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2qH_erepGhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE GUIDE TO MATRIX MULTIPLICATION AND OPERATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create sample tensors for demonstration\n",
        "A = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])  # Shape: [2, 3]\n",
        "\n",
        "B = torch.tensor([[7, 8],\n",
        "                  [9, 10],\n",
        "                  [11, 12]])  # Shape: [3, 2]\n",
        "\n",
        "C = torch.tensor([[2, 3],\n",
        "                  [4, 5]])  # Shape: [2, 2]\n",
        "\n",
        "v = torch.tensor([1, 2, 3])  # Shape: [3]\n",
        "\n",
        "print(\"\\nSample Tensors:\")\n",
        "print(f\"A (2×3):\\n{A}\")\n",
        "print(f\"\\nB (3×2):\\n{B}\")\n",
        "print(f\"\\nC (2×2):\\n{C}\")\n",
        "print(f\"\\nv (3):\\n{v}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. ELEMENT-WISE MULTIPLICATION (Hadamard Product)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"1. ELEMENT-WISE MULTIPLICATION: * operator\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nRequirement: Shapes must be EXACTLY the same (or broadcastable)\")\n",
        "print(\"\\nC * C (element-wise):\")\n",
        "result = C * C\n",
        "print(f\"[[2, 3],   *  [[2, 3],   =  [[2*2, 3*3],   =  {result.tolist()}\")\n",
        "print(f\" [4, 5]]       [4, 5]]       [4*4, 5*5]]\")\n",
        "\n",
        "print(\"\\nBroadcasting example:\")\n",
        "scalar = torch.tensor([2, 3])  # Shape: [2]\n",
        "print(f\"C * [2, 3] (broadcasts to each row):\")\n",
        "result = C * scalar\n",
        "print(f\"Result:\\n{result}\")\n",
        "print(f\"Explanation: [[2,3], * [2,3] = [[2*2, 3*3], = [[4, 9],\")\n",
        "print(f\"              [4,5]]            [4*2, 5*3]]    [8, 15]]\")\n",
        "\n",
        "print(\"\\n⚠️  ERROR if shapes don't match:\")\n",
        "try:\n",
        "    result = A * B  # [2,3] * [3,2] - doesn't work!\n",
        "    print(result)\n",
        "except RuntimeError as e:\n",
        "    print(f\"A * B fails: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. MATRIX MULTIPLICATION: @ operator and torch.matmul()\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"2. MATRIX MULTIPLICATION: @ operator or torch.matmul()\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nRequirement: Inner dimensions must match: (m×n) @ (n×p) = (m×p)\")\n",
        "print(\"\\nA @ B:\")\n",
        "print(f\"Shape: [2, 3] @ [3, 2] = [2, 2]\")\n",
        "result = A @ B\n",
        "print(f\"Result:\\n{result}\")\n",
        "\n",
        "print(\"\\nDetailed calculation:\")\n",
        "print(\"[[1, 2, 3],   [[7,  8 ],   [[1*7+2*9+3*11,  1*8+2*10+3*12],\")\n",
        "print(\" [4, 5, 6]] @  [9,  10],  = [4*7+5*9+6*11,  4*8+5*10+6*12]]\")\n",
        "print(\"               [11, 12]]\")\n",
        "print(f\"             = [[58, 64],\")\n",
        "print(f\"                [139, 154]]\")\n",
        "\n",
        "print(\"\\ntorch.matmul(A, B) gives same result:\")\n",
        "result2 = torch.matmul(A, B)\n",
        "print(f\"Result:\\n{result2}\")\n",
        "\n",
        "print(\"\\n⚠️  ERROR if inner dimensions don't match:\")\n",
        "try:\n",
        "    result = A @ A  # [2,3] @ [2,3] - doesn't work!\n",
        "except RuntimeError as e:\n",
        "    print(f\"A @ A fails: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olVDjE8TpGel",
        "outputId": "01ff95d9-d74d-4ed0-a17d-59e4725584ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE GUIDE TO MATRIX MULTIPLICATION AND OPERATIONS\n",
            "================================================================================\n",
            "\n",
            "Sample Tensors:\n",
            "A (2×3):\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "B (3×2):\n",
            "tensor([[ 7,  8],\n",
            "        [ 9, 10],\n",
            "        [11, 12]])\n",
            "\n",
            "C (2×2):\n",
            "tensor([[2, 3],\n",
            "        [4, 5]])\n",
            "\n",
            "v (3):\n",
            "tensor([1, 2, 3])\n",
            "\n",
            "================================================================================\n",
            "1. ELEMENT-WISE MULTIPLICATION: * operator\n",
            "================================================================================\n",
            "\n",
            "Requirement: Shapes must be EXACTLY the same (or broadcastable)\n",
            "\n",
            "C * C (element-wise):\n",
            "[[2, 3],   *  [[2, 3],   =  [[2*2, 3*3],   =  [[4, 9], [16, 25]]\n",
            " [4, 5]]       [4, 5]]       [4*4, 5*5]]\n",
            "\n",
            "Broadcasting example:\n",
            "C * [2, 3] (broadcasts to each row):\n",
            "Result:\n",
            "tensor([[ 4,  9],\n",
            "        [ 8, 15]])\n",
            "Explanation: [[2,3], * [2,3] = [[2*2, 3*3], = [[4, 9],\n",
            "              [4,5]]            [4*2, 5*3]]    [8, 15]]\n",
            "\n",
            "⚠️  ERROR if shapes don't match:\n",
            "A * B fails: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n",
            "\n",
            "================================================================================\n",
            "2. MATRIX MULTIPLICATION: @ operator or torch.matmul()\n",
            "================================================================================\n",
            "\n",
            "Requirement: Inner dimensions must match: (m×n) @ (n×p) = (m×p)\n",
            "\n",
            "A @ B:\n",
            "Shape: [2, 3] @ [3, 2] = [2, 2]\n",
            "Result:\n",
            "tensor([[ 58,  64],\n",
            "        [139, 154]])\n",
            "\n",
            "Detailed calculation:\n",
            "[[1, 2, 3],   [[7,  8 ],   [[1*7+2*9+3*11,  1*8+2*10+3*12],\n",
            " [4, 5, 6]] @  [9,  10],  = [4*7+5*9+6*11,  4*8+5*10+6*12]]\n",
            "               [11, 12]]\n",
            "             = [[58, 64],\n",
            "                [139, 154]]\n",
            "\n",
            "torch.matmul(A, B) gives same result:\n",
            "Result:\n",
            "tensor([[ 58,  64],\n",
            "        [139, 154]])\n",
            "\n",
            "⚠️  ERROR if inner dimensions don't match:\n",
            "A @ A fails: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 3. torch.mm() - Matrix-Matrix multiplication (2D only)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"3. torch.mm() - Strictly 2D Matrix Multiplication\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nRequirement: Both inputs must be 2D matrices\")\n",
        "print(\"\\ntorch.mm(A, B):\")\n",
        "result = torch.mm(A, B)\n",
        "print(f\"Result:\\n{result}\")\n",
        "\n",
        "print(\"\\n⚠️  ERROR with non-2D tensors:\")\n",
        "try:\n",
        "    result = torch.mm(A, v)  # v is 1D\n",
        "except RuntimeError as e:\n",
        "    print(f\"torch.mm(A, v) fails: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. torch.mv() - Matrix-Vector multiplication\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"4. torch.mv() - Matrix-Vector Multiplication\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nRequirement: matrix (2D) × vector (1D)\")\n",
        "print(\"\\ntorch.mv(A, v):\")\n",
        "result = torch.mv(A, v)\n",
        "print(f\"Shape: [2, 3] × [3] = [2]\")\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "print(\"\\nDetailed calculation:\")\n",
        "print(\"[[1, 2, 3],   [1]     [1*1 + 2*2 + 3*3]   [14]\")\n",
        "print(\" [4, 5, 6]] × [2]  =  [4*1 + 5*2 + 6*3] = [32]\")\n",
        "print(\"              [3]\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. torch.bmm() - Batch Matrix Multiplication\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"5. torch.bmm() - Batch Matrix Multiplication\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nRequirement: Both inputs 3D with same batch size: (b×m×n) @ (b×n×p) = (b×m×p)\")\n",
        "\n",
        "batch_A = torch.randn(10, 3, 4)  # batch=10, 3×4 matrices\n",
        "batch_B = torch.randn(10, 4, 5)  # batch=10, 4×5 matrices\n",
        "\n",
        "result = torch.bmm(batch_A, batch_B)\n",
        "print(f\"Shape: [10, 3, 4] @ [10, 4, 5] = {list(result.shape)}\")\n",
        "print(\"Performs 10 separate matrix multiplications (one per batch)\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. Broadcasting with @ and torch.matmul()\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"6. BROADCASTING with @ and torch.matmul()\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\ntorch.matmul() supports broadcasting for batch dimensions!\")\n",
        "\n",
        "# Example 1: Broadcasting batch dimension\n",
        "A_batched = torch.randn(5, 2, 3)  # 5 batches of 2×3 matrices\n",
        "B_single = torch.randn(3, 4)      # Single 3×4 matrix\n",
        "\n",
        "result = torch.matmul(A_batched, B_single)\n",
        "print(f\"\\nExample 1 - Broadcast single matrix to all batches:\")\n",
        "print(f\"[5, 2, 3] @ [3, 4] = {list(result.shape)}\")\n",
        "print(\"The [3,4] matrix broadcasts to all 5 batches\")\n",
        "\n",
        "# Example 2: Different batch sizes\n",
        "A_batch = torch.randn(10, 1, 2, 3)  # batch shape [10, 1]\n",
        "B_batch = torch.randn(1, 5, 3, 4)   # batch shape [1, 5]\n",
        "\n",
        "result = torch.matmul(A_batch, B_batch)\n",
        "print(f\"\\nExample 2 - Broadcast both batch dimensions:\")\n",
        "print(f\"[10, 1, 2, 3] @ [1, 5, 3, 4] = {list(result.shape)}\")\n",
        "print(\"Batch dims [10,1] and [1,5] broadcast to [10,5]\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. torch.dot() - Dot product (1D only)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"7. torch.dot() - Dot Product (1D vectors only)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "u = torch.tensor([1, 2, 3])\n",
        "v = torch.tensor([4, 5, 6])\n",
        "\n",
        "result = torch.dot(u, v)\n",
        "print(f\"u: {u}\")\n",
        "print(f\"v: {v}\")\n",
        "print(f\"torch.dot(u, v) = {result}\")\n",
        "print(\"Calculation: 1*4 + 2*5 + 3*6 = 32\")\n",
        "\n",
        "print(\"\\n⚠️  ERROR with 2D tensors:\")\n",
        "try:\n",
        "    result = torch.dot(C, C)\n",
        "except RuntimeError as e:\n",
        "    print(f\"torch.dot(C, C) fails: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. Einstein Summation: torch.einsum()\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"8. torch.einsum() - Einstein Summation (Most Flexible!)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nVery powerful notation for complex operations\")\n",
        "\n",
        "# Matrix multiplication\n",
        "result = torch.einsum('ij,jk->ik', A, B)\n",
        "print(f\"\\nMatrix mult: 'ij,jk->ik'\")\n",
        "print(f\"A @ B:\\n{result}\")\n",
        "\n",
        "# Batch matrix multiplication\n",
        "batch_A = torch.randn(10, 3, 4)\n",
        "batch_B = torch.randn(10, 4, 5)\n",
        "result = torch.einsum('bij,bjk->bik', batch_A, batch_B)\n",
        "print(f\"\\nBatch matrix mult: 'bij,bjk->bik'\")\n",
        "print(f\"Shape: {list(result.shape)}\")\n",
        "\n",
        "# Transpose\n",
        "result = torch.einsum('ij->ji', A)\n",
        "print(f\"\\nTranspose: 'ij->ji'\")\n",
        "print(f\"Result:\\n{result}\")\n",
        "\n",
        "# Diagonal sum (trace)\n",
        "result = torch.einsum('ii->', C)\n",
        "print(f\"\\nTrace (diagonal sum): 'ii->'\")\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "# Element-wise multiplication then sum\n",
        "result = torch.einsum('ij,ij->', C, C)\n",
        "print(f\"\\nElement-wise mult then sum: 'ij,ij->'\")\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 9. COMPARISON TABLE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"9. QUICK REFERENCE TABLE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "table = \"\"\"\n",
        "┌─────────────────┬──────────────────┬─────────────────────────────────┐\n",
        "│ Operation       │ Syntax           │ Requirements                    │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Element-wise    │ A * B            │ Same shape (or broadcastable)   │\n",
        "│ multiplication  │                  │                                 │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Matrix mult     │ A @ B            │ (m×n) @ (n×p) = (m×p)          │\n",
        "│                 │ torch.matmul()   │ Supports broadcasting           │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Matrix mult     │ torch.mm(A, B)   │ Strictly 2D matrices            │\n",
        "│ (2D only)       │                  │ No broadcasting                 │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Matrix-vector   │ torch.mv(A, v)   │ A: 2D matrix, v: 1D vector     │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Batch matrix    │ torch.bmm(A, B)  │ Both 3D, same batch size       │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Dot product     │ torch.dot(u, v)  │ Both 1D vectors, same length   │\n",
        "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
        "│ Einstein sum    │ torch.einsum()   │ Flexible notation for any op   │\n",
        "└─────────────────┴──────────────────┴─────────────────────────────────┘\n",
        "\"\"\"\n",
        "print(table)\n",
        "\n",
        "# ============================================================================\n",
        "# 10. COMMON PITFALLS AND SOLUTIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"10. COMMON PITFALLS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n❌ PITFALL 1: Using * instead of @ for matrix multiplication\")\n",
        "print(\"Solution: Use @ or torch.matmul() for matrix multiplication\")\n",
        "\n",
        "print(\"\\n❌ PITFALL 2: Dimension mismatch\")\n",
        "print(\"Solution: Check shapes with .shape before operations\")\n",
        "print(f\"Example: A.shape = {A.shape}, B.shape = {B.shape}\")\n",
        "\n",
        "print(\"\\n❌ PITFALL 3: 1D vector as matrix row/column\")\n",
        "v = torch.tensor([1, 2, 3])\n",
        "print(f\"v.shape = {v.shape} (1D)\")\n",
        "print(\"To make column: v.unsqueeze(1) →\", v.unsqueeze(1).shape)\n",
        "print(\"To make row: v.unsqueeze(0) →\", v.unsqueeze(0).shape)\n",
        "\n",
        "print(\"\\n❌ PITFALL 4: Using torch.mm() with batches\")\n",
        "print(\"Solution: Use torch.bmm() or torch.matmul() for batched operations\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. PRACTICAL EXAMPLES FROM TRANSFORMERS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"11. TRANSFORMER EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "batch_size, seq_len, d_model = 32, 10, 128\n",
        "num_heads, d_k = 8, 16\n",
        "\n",
        "# Example: Multi-head attention\n",
        "Q = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
        "K = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
        "V = torch.randn(batch_size, num_heads, seq_len, d_k)\n",
        "\n",
        "print(\"\\nAttention scores: Q @ K^T\")\n",
        "print(f\"Q shape: {list(Q.shape)}\")\n",
        "print(f\"K.transpose(-2, -1) shape: {list(K.transpose(-2, -1).shape)}\")\n",
        "\n",
        "attn_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
        "print(f\"Result shape: {list(attn_scores.shape)}\")\n",
        "print(\"Performs batch matrix mult: [32,8,10,16] @ [32,8,16,10] = [32,8,10,10]\")\n",
        "\n",
        "print(\"\\nAttention output: attn_probs @ V\")\n",
        "attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "output = torch.matmul(attn_probs, V)\n",
        "print(f\"Result shape: {list(output.shape)}\")\n",
        "print(\"[32,8,10,10] @ [32,8,10,16] = [32,8,10,16]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"END OF GUIDE\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzqs32bYpGbN",
        "outputId": "c885cf62-d037-421d-f8ea-6af213afdaa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "3. torch.mm() - Strictly 2D Matrix Multiplication\n",
            "================================================================================\n",
            "\n",
            "Requirement: Both inputs must be 2D matrices\n",
            "\n",
            "torch.mm(A, B):\n",
            "Result:\n",
            "tensor([[ 58,  64],\n",
            "        [139, 154]])\n",
            "\n",
            "⚠️  ERROR with non-2D tensors:\n",
            "torch.mm(A, v) fails: mat2 must be a matrix\n",
            "\n",
            "================================================================================\n",
            "4. torch.mv() - Matrix-Vector Multiplication\n",
            "================================================================================\n",
            "\n",
            "Requirement: matrix (2D) × vector (1D)\n",
            "\n",
            "torch.mv(A, v):\n",
            "Shape: [2, 3] × [3] = [2]\n",
            "Result: tensor([14, 32])\n",
            "\n",
            "Detailed calculation:\n",
            "[[1, 2, 3],   [1]     [1*1 + 2*2 + 3*3]   [14]\n",
            " [4, 5, 6]] × [2]  =  [4*1 + 5*2 + 6*3] = [32]\n",
            "              [3]\n",
            "\n",
            "================================================================================\n",
            "5. torch.bmm() - Batch Matrix Multiplication\n",
            "================================================================================\n",
            "\n",
            "Requirement: Both inputs 3D with same batch size: (b×m×n) @ (b×n×p) = (b×m×p)\n",
            "Shape: [10, 3, 4] @ [10, 4, 5] = [10, 3, 5]\n",
            "Performs 10 separate matrix multiplications (one per batch)\n",
            "\n",
            "================================================================================\n",
            "6. BROADCASTING with @ and torch.matmul()\n",
            "================================================================================\n",
            "\n",
            "torch.matmul() supports broadcasting for batch dimensions!\n",
            "\n",
            "Example 1 - Broadcast single matrix to all batches:\n",
            "[5, 2, 3] @ [3, 4] = [5, 2, 4]\n",
            "The [3,4] matrix broadcasts to all 5 batches\n",
            "\n",
            "Example 2 - Broadcast both batch dimensions:\n",
            "[10, 1, 2, 3] @ [1, 5, 3, 4] = [10, 5, 2, 4]\n",
            "Batch dims [10,1] and [1,5] broadcast to [10,5]\n",
            "\n",
            "================================================================================\n",
            "7. torch.dot() - Dot Product (1D vectors only)\n",
            "================================================================================\n",
            "u: tensor([1, 2, 3])\n",
            "v: tensor([4, 5, 6])\n",
            "torch.dot(u, v) = 32\n",
            "Calculation: 1*4 + 2*5 + 3*6 = 32\n",
            "\n",
            "⚠️  ERROR with 2D tensors:\n",
            "torch.dot(C, C) fails: 1D tensors expected, but got 2D and 2D tensors\n",
            "\n",
            "================================================================================\n",
            "8. torch.einsum() - Einstein Summation (Most Flexible!)\n",
            "================================================================================\n",
            "\n",
            "Very powerful notation for complex operations\n",
            "\n",
            "Matrix mult: 'ij,jk->ik'\n",
            "A @ B:\n",
            "tensor([[ 58,  64],\n",
            "        [139, 154]])\n",
            "\n",
            "Batch matrix mult: 'bij,bjk->bik'\n",
            "Shape: [10, 3, 5]\n",
            "\n",
            "Transpose: 'ij->ji'\n",
            "Result:\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "\n",
            "Trace (diagonal sum): 'ii->'\n",
            "Result: 7\n",
            "\n",
            "Element-wise mult then sum: 'ij,ij->'\n",
            "Result: 54\n",
            "\n",
            "================================================================================\n",
            "9. QUICK REFERENCE TABLE\n",
            "================================================================================\n",
            "\n",
            "┌─────────────────┬──────────────────┬─────────────────────────────────┐\n",
            "│ Operation       │ Syntax           │ Requirements                    │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Element-wise    │ A * B            │ Same shape (or broadcastable)   │\n",
            "│ multiplication  │                  │                                 │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Matrix mult     │ A @ B            │ (m×n) @ (n×p) = (m×p)          │\n",
            "│                 │ torch.matmul()   │ Supports broadcasting           │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Matrix mult     │ torch.mm(A, B)   │ Strictly 2D matrices            │\n",
            "│ (2D only)       │                  │ No broadcasting                 │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Matrix-vector   │ torch.mv(A, v)   │ A: 2D matrix, v: 1D vector     │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Batch matrix    │ torch.bmm(A, B)  │ Both 3D, same batch size       │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Dot product     │ torch.dot(u, v)  │ Both 1D vectors, same length   │\n",
            "├─────────────────┼──────────────────┼─────────────────────────────────┤\n",
            "│ Einstein sum    │ torch.einsum()   │ Flexible notation for any op   │\n",
            "└─────────────────┴──────────────────┴─────────────────────────────────┘\n",
            "\n",
            "\n",
            "================================================================================\n",
            "10. COMMON PITFALLS\n",
            "================================================================================\n",
            "\n",
            "❌ PITFALL 1: Using * instead of @ for matrix multiplication\n",
            "Solution: Use @ or torch.matmul() for matrix multiplication\n",
            "\n",
            "❌ PITFALL 2: Dimension mismatch\n",
            "Solution: Check shapes with .shape before operations\n",
            "Example: A.shape = torch.Size([2, 3]), B.shape = torch.Size([3, 2])\n",
            "\n",
            "❌ PITFALL 3: 1D vector as matrix row/column\n",
            "v.shape = torch.Size([3]) (1D)\n",
            "To make column: v.unsqueeze(1) → torch.Size([3, 1])\n",
            "To make row: v.unsqueeze(0) → torch.Size([1, 3])\n",
            "\n",
            "❌ PITFALL 4: Using torch.mm() with batches\n",
            "Solution: Use torch.bmm() or torch.matmul() for batched operations\n",
            "\n",
            "================================================================================\n",
            "11. TRANSFORMER EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "Attention scores: Q @ K^T\n",
            "Q shape: [32, 8, 10, 16]\n",
            "K.transpose(-2, -1) shape: [32, 8, 16, 10]\n",
            "Result shape: [32, 8, 10, 10]\n",
            "Performs batch matrix mult: [32,8,10,16] @ [32,8,16,10] = [32,8,10,10]\n",
            "\n",
            "Attention output: attn_probs @ V\n",
            "Result shape: [32, 8, 10, 16]\n",
            "[32,8,10,10] @ [32,8,10,16] = [32,8,10,16]\n",
            "\n",
            "================================================================================\n",
            "END OF GUIDE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oX7NdZwUpGSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRTc7s27pGFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}